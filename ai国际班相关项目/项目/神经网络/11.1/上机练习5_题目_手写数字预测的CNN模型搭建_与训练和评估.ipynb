{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d4c08f48-fe23-4ddb-ac46-d97f05397514",
    "_uuid": "f2156d1dd26a1243e18512002e10872c5bd7271e"
   },
   "source": [
    "* **1. Introduction**\n",
    "* **2. Data preparation**\n",
    "    * 2.1 Load data\n",
    "    * 2.2 Check for null and missing values\n",
    "    * 2.3 Normalization\n",
    "    * 2.4 Reshape\n",
    "    * 2.5 Label encoding\n",
    "    * 2.6 Split training and valdiation set\n",
    "* **3. CNN**\n",
    "\n",
    "* **4. Evaluate the model**\n",
    "\n",
    "* **5. Prediction and submition**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "eb88b372-a6e5-40c8-a1c6-c03799165490",
    "_uuid": "e9aff3cf1bb8daa73bec67b970d12195677679f3"
   },
   "source": [
    "# 1. Introduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f67b9393-8ea1-4e23-b856-2ce149cfe421",
    "_execution_state": "idle",
    "_uuid": "72334cb006d02a4bcfc2a2fe622524eba824c6f8",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6d2fb3e6-ab71-4974-b5a2-4af1ebdb99f4",
    "_execution_state": "idle",
    "_uuid": "86061d98eccaa02efe0dab0fa3884e71fcf4c310"
   },
   "source": [
    "# 2. Data preparation\n",
    "## 2.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5e51d00e-62fd-4141-bf73-50ac4f2da7d0",
    "_execution_state": "idle",
    "_uuid": "84bbd5ab8d7895bd430d5ecfe2f7ddf77baa7b74",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# >>>>>填写<<<< 利用pandas的load_csv函数，读取我们的train 和 test数据集合 变量已经给出 >>>>>填写<<<< ######\n",
    "train = pd.read_csv(\"C:/Users/H/Desktop/AI/11.1/subset_train.csv\")\n",
    "test = pd.read_csv(\"C:/Users/H/Desktop/AI/11.1/Small_test.csv\")\n",
    "#####train validation test(完全独立的，与训练过程无关的)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "86570a36-5c20-460a-9dfd-2070548532a7",
    "_execution_state": "idle",
    "_uuid": "1213b979d5ed3e0d13824d17d694c79d2ece92fa",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# >>>>>填写<<<< 利用pandas的header选择，将label列传递给Y_train >>>>>填写<<<< \n",
    "Y_train = train[\"label\"]\n",
    "Y_test = test['label']\n",
    "# 因为train.csv中，第一列label在上述代码已经传递给Y_label，这里对于x_train 我们不需要训练集的第一列 #####\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "X_test = test.drop(labels = [\"label\"],axis = 1)\n",
    "\n",
    "\n",
    "g = sns.countplot(Y_train)\n",
    "\n",
    "Y_train.value_counts()\n",
    "Y_train\n",
    "Y_test.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5aea4062-1790-4987-b739-c4bebd79030f",
    "_uuid": "b7b1b1d36243c885e57374c8b60c5a7e10abe922"
   },
   "source": [
    "## We have similar counts for the 10 digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5b7d4b66-a140-4fcc-a889-bcef007c880a",
    "_uuid": "5d77934302869925c19128c77e247b3c8ca84d71"
   },
   "source": [
    "## 2.2 Check for null and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ececaa00-2ae3-4d13-b631-438df085b030",
    "_execution_state": "idle",
    "_uuid": "cdf27c27e2a5b15e6d7bfc70de7a18c08f3feb7a",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 检查训练数据是否有空值\n",
    "X_train.isnull().any().describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "92572e80-8543-4e72-8767-5c9be8381b04",
    "_execution_state": "idle",
    "_uuid": "a0089bb7ec9aec76373db475399aea24699ae989",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# >>>>填写<<<< 检查训练数据是否有空值 >>>>填写<<<< ###\n",
    "X_test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "09d04cae-4245-4659-85dd-ef48531da295",
    "_uuid": "c0bee59691c2df0b275c78e38e7f9907d02ac038"
   },
   "source": [
    "I check for corrupted images (missing values inside).\n",
    "\n",
    "There is no missing values in the train and test dataset. So we can safely go ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6812040d-80ad-43d2-a571-275f4f20067b",
    "_uuid": "2954681f25f0dcbe986e6914396cdbce61db591f"
   },
   "source": [
    "## 2.3 Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "159d5854-437a-4d0f-bc1e-fc3f7e43d178",
    "_uuid": "0ecf4b52510ab7957d0d4eb646c0aa1ba5986273"
   },
   "source": [
    "We perform a grayscale normalization to reduce the effect of illumination's differences. \n",
    "\n",
    "Moreover the CNN converg faster on [0..1] data than on [0..255].\n",
    "标准化，将灰度值 0-255 映射到0 - 1区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cdc4340b-6e24-4e12-be99-ac806098ff17",
    "_execution_state": "idle",
    "_uuid": "b5d4f8fcf2a967e2c7d57daedf95aa8c5ab7f8cb",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "###### >>>填写<<< 标准化测试集合 #######\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7413df94-bcb9-4f75-b174-c127d4445766",
    "_uuid": "a66741bf1ac597094f3a3166877008feef27c519"
   },
   "source": [
    "## 2.3 Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "34b6a5f7-8fd2-4387-8ef4-c9dc19584fed",
    "_execution_state": "idle",
    "_uuid": "f0a6ad80dab8e0f2c2e46165ccd9cd82dd162bc3",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# >>>>填写<<<<< 利用 reshape 函数， 将X_train变换成 (height = 28px, width = 28px , canal = 1)>>>>填写<<<<< ######\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "X_test = X_test.values.reshape(-1,28,28,1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8decd1ce-7b7e-431d-8458-eaca18e0e1f7",
    "_uuid": "f4fb5553e188d9956f5d8b3a5d275ab00ea667ce"
   },
   "source": [
    "Train and test images (28px x 28px) has been stock into pandas.Dataframe as 1D vectors of 784 values. We reshape all data to 28x28x1 3D matrices. \n",
    "# 训练和测试图像(28px x 28px)已经存入pandas。Dataframe是值为784的一维向量。我们将所有数据重塑为28x28x1 3D矩阵。\n",
    "\n",
    "Keras requires an extra dimension in the end which correspond to channels. MNIST images are gray scaled so it use only one channel. For RGB images, there is 3 channels, we would have reshaped 784px vectors to 28x28x3 3D matrices.\n",
    "# Keras在最后需要一个额外的维度来对应通道。MNIST图像是灰度的，所以它只使用一个通道。对于RGB图像，有3个通道，我们将把784px的向量重塑为28x28x3的3D矩阵。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bdb422e2-bdec-444f-97a5-283a1e54bf2c",
    "_uuid": "39b7a31e843bac6b705461bcce89da216b91799e"
   },
   "source": [
    "## 2.5 Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4b7f3e78-44dc-4561-b1f0-9429ee024cf4",
    "_execution_state": "idle",
    "_uuid": "cabefd1478d5c1bdfe57fd6a34395340916a854c",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 利用0 1编码 将0-9数字标签编码成10维向量 (ex : 9 -> [0,0,0,0,0,0,0,0,0,1])\n",
    "##\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "Y_test = to_categorical(Y_test, num_classes = 10)\n",
    "## one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ae068bd8-b12e-4768-8a7e-0fc865dd7562",
    "_uuid": "dcfb688587dfc6feafd27442a3505e35dc01b82d"
   },
   "source": [
    "Labels are 10 digits numbers from 0 to 9. We need to encode these lables to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "32152fc3-a570-4d64-8a7d-6c689a4acd33",
    "_uuid": "d8abbbf31483b94e1b29d07c4c8253d1311648a7"
   },
   "source": [
    "## 2.6 Split training and valdiation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3a698301-9759-4279-ae48-fd980f89ea53",
    "_execution_state": "idle",
    "_uuid": "6e51c925c6e0f1b936679c9649fef345c853555f",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Set the random_seed\n",
    "# 随机设置数\n",
    "random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dcd25ebb-d845-4d32-9867-082e352b1396",
    "_execution_state": "idle",
    "_uuid": "b779ac76d8317647db92d5a88b4098d212d72884",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 将训练集合按照9:1 分成训练集合 和验证集合 validation 10折交叉验证 10-fold validation  ####\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "adbeacf0-0dc0-4675-b2df-9c9663750f32",
    "_uuid": "60eed15ec5bc0d354385301789ecb8538fc02267"
   },
   "source": [
    "We can get a better sense for one of these examples by visualising the image and looking at the label.\n",
    "# 我们可以通过可视化图像和查看标签来更好地理解这些例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5f76131b-4ba0-45f1-a98c-bd4e7d561793",
    "_execution_state": "idle",
    "_uuid": "e0dae8943d3d35f075dba3d7ba31bde1d4bf2ff4",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Some examples #x-train里面第一个sample的 0:最大 0:最大 0 [:,:,0] \n",
    "g = plt.imshow(X_train[0][:,:,0],cmap='gray') #plt为什么把灰度可以生"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d5265777-aeb3-449d-b171-d88cad74c0a4",
    "_uuid": "5fa18b37a9acd9e098bac1d12264b0dd4310fdd3"
   },
   "source": [
    "# 3. CNN\n",
    "## 3.1 Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "504fa00e-148c-4364-9b68-218b3aaedfdb",
    "_uuid": "7697570491420f957f6e4d3569d51410b5277250"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#####  填写 batch_size epoch 请根据traindata 总量填写合适的值 ####\n",
    "##### 我们的分配数量num_classes,提示 我们的任务是手写体0-9的识别 ####### \n",
    "\n",
    "batch_size = 64\n",
    "num_classes = 10 \n",
    "epochs = 20\n",
    "\n",
    "input_shape = (28,28,1)\n",
    "\n",
    "#构建CNN 模型 这里我们利用Sequential 序列累加 ######\n",
    "model = Sequential()\n",
    "## 第一个 卷积层 32个kernel kernel大小3*3 输出的激活函数relu kernel利用 He-正态分布 生成  ####\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',input_shape=input_shape))\n",
    "\n",
    "# # （28-3+2*0）/1+1 得到32个feature Maps  大小（26*26）\n",
    "\n",
    "###  请自行构建第二个卷积层，此时kernel的初始尝试用全零初始/全1初始/正态初始\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal'))\n",
    "\n",
    "#（26-3+2*0）/1+1 得到32个feature Maps  大小（24*24）\n",
    "\n",
    "### 构建一个最大池化层 \n",
    "model.add(MaxPool2D((2, 2),strides=2))\n",
    "\n",
    "#（24-2+2*0）/2+1 得到 得到32个feature Maps 大小（12*12\n",
    "\n",
    "model.add(Dropout(0.20))\n",
    "###  在下述卷积层内 构建一个padding, 在之后构建一个kernel size = 2 *2 的池化层 \n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\n",
    "\n",
    "# （12-3+2*1）/1+1 得到 64个feature Maps  大小（12*12）\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# （12-2+2*0）/2+1 得到  64个feature Maps  大小（6*6）\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "###  构建一个全联接 其中包含128个神经元 并使用relu激活函数\n",
    "\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "###  构建一个全联接，该全联接需要用特定的激活函数和适当的神经元个数 来实现我们的分类目标  提示：我们有多少个标签？什么激活适合最后的输出？\n",
    "model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a4c55409-6a65-400a-b5e8-a1dc535429c0",
    "_execution_state": "idle",
    "_uuid": "420c704367b397b8255fefe9d882b35ac8929b95",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "### 运行model.summary（）回答下列问题 第二天课上一起讨论 ####\n",
    "### 能否画出这个模型的概括图?  >>>\n",
    "\n",
    "### 这个模型有几个卷积层？ 3\n",
    "### 这个模型最大的参数量是哪一层？  full - connection\n",
    "### 第一层卷积层为什么有320个实际变量需要调节       32 * 9 + 32 * 1 (W,bias)  y=wx+b\n",
    "\n",
    "\n",
    "#最后一层 max——pooling完 有64个6*6 feature maps 64*6*6 = 2304\n",
    "\n",
    "### para = 2304*128 + 128 #128个w,b\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#优化器  尝试使用不同的优化器 至少以下三种\n",
    "## 中文参考 https://keras.io/zh/optimizers/\n",
    "## \n",
    "## SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "'''\n",
    "参数\n",
    "lr: float >= 0. 学习率。\n",
    "momentum: float >= 0. 参数，用于加速 SGD 在相关方向上前进，并抑制震荡。\n",
    "decay: float >= 0. 每次参数更新后学习率衰减值。\n",
    "nesterov: boolean. 是否使用 Nesterov 动量。'''\n",
    "\n",
    "## RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "'''\n",
    "参数\n",
    "lr: float >= 0. 学习率。\n",
    "rho: float >= 0. RMSProp梯度平方的移动均值的衰减率.\n",
    "epsilon: float >= 0. 模糊因子. 若为 None, 默认为 K.epsilon()。\n",
    "decay: float >= 0. 每次参数更新后学习率衰减值。\n",
    "'''\n",
    "\n",
    "## Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "'''\n",
    "参数\n",
    "lr: float >= 0. 学习率.\n",
    "epsilon: float >= 0. 若为 None, 默认为 K.epsilon().\n",
    "decay: float >= 0. 每次参数更新后学习率衰减值.\n",
    "'''\n",
    "\n",
    "optimizer = RMSprop(lr=0.01, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "### 将模型compile 编译\n",
    "### 调节loss 参数，即loss function\n",
    "### mean_squared_error\n",
    "### categorical_crossentropy/为什么不用binary_crossentropy\n",
    "### mean_absolute_error \n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\" , metrics=[\"accuracy\"])\n",
    "\n",
    "### training 过程中的 自动调节函数\n",
    "### Reduce LR On Plateau = 减少学习率，当某一个参数达到一个平台期 自动的 把上面优化器中的 lr 减小\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 384/3780 [==>...........................] - ETA: 8s - loss: 0.0092 - acc: 0.9974"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 训练模型 注意填写缺失参数 记得用变量形式填写\n",
    "history = model.fit(X_train,Y_train, batch_size=batch_size,\n",
    "                              epochs = epochs , validation_data = (X_val,Y_val),callbacks=[learning_rate_reduction])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 生成学习曲线 和损失函数 随着epoch的变化曲线\n",
    "# 模型的学习效果怎么样？ 能找到适合的epoch吗？\n",
    "# 简单的评价标准应该用什么？\n",
    "# 尝试改变模型参数 生成不同的学习曲线 比较\n",
    "# 提示 从epoch>优化器>损失函数>学习率>dropout有无 依次调试 \n",
    "fig, ax = plt.subplots(2,1)\n",
    "\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 生成10标签混淆矩阵\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_val,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "### 打印出认错的数字\n",
    "\n",
    "errors = (Y_pred_classes - Y_true != 0)\n",
    "\n",
    "Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "Y_pred_errors = Y_pred[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_val_errors = X_val[errors]\n",
    "\n",
    "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = 3\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n",
    "\n",
    "# Probabilities of the wrong predicted numbers\n",
    "Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "\n",
    "# Top 9 errors \n",
    "most_important_errors = sorted_dela_errors[-9:]\n",
    "\n",
    "# Show the top 9 errors\n",
    "display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#optional 计算每个标签的tpr fpr\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "y_score = model.predict(X_test)\n",
    "for i in range(num_classes):\n",
    "     fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], y_score[:, i])\n",
    "    # AUC Area Under the Curve\n",
    "     roc_auc[i] = auc(fpr[i], tpr[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#画出ROC\n",
    "for i in range(num_classes):\n",
    "    plt.plot()\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "# 打印出模型图片 尝试自己改动模型 \n",
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}